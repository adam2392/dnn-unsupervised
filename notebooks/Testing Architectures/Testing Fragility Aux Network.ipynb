{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam2392/Documents/dnn-unsupervised/.venv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../dnn/')\n",
    "from model.nets.fragilityaux import CNNFragility\n",
    "from model.nets.ieegcnn import iEEGCNN\n",
    "from model.nets.ieegseq import iEEGSeq\n",
    "\n",
    "import model.train\n",
    "from model.train import traincnn, trainseq\n",
    "\n",
    "\n",
    "import processing.util as util\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "# np.random.seed(1234)\n",
    "import math as m\n",
    "import os\n",
    "\n",
    "# import DNN frameworks\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# import high level optimizers, models and layers\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "# utility for datasets and training\n",
    "# from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "# imports tensorflow\n",
    "# from keras import backend as K\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/adam2392/Documents/dnn-unsupervised/.venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "{'DROPOUT': True,\n",
      " 'filteringsize': (3,),\n",
      " 'imsize': 30,\n",
      " 'numchans': 1,\n",
      " 'numclasses': 2,\n",
      " 'numfilters': 32,\n",
      " 'numlayers': (4, 2, 1),\n",
      " 'poolingsize': (2,),\n",
      " 'w_init': None}\n",
      "[(None, 500, 1), (None, 30, 500, 1)]\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 30, 500, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 498, 32)      128         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 29, 495, 32)  416         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 496, 32)      3104        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 490, 32)  12320       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 494, 32)      3104        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 27, 485, 32)  12320       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 492, 32)      3104        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 26, 480, 32)  12320       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 246, 32)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 13, 120, 32)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 244, 64)      6208        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 12, 115, 64)  24640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 242, 64)      12352       conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 11, 110, 64)  49216       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 121, 64)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 5, 27, 64)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 119, 128)     24704       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 4, 22, 128)   98432       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 59, 128)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 5, 128)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 7552)         0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1280)         0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8832)         0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          4522496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          262656      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          262656      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            1026        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,311,202\n",
      "Trainable params: 5,311,202\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "imsize=30    # the size of the PCA that you perform on the rest of the fragility map\n",
    "n_colors=1\n",
    "num_classes=2\n",
    "num_timesteps=150\n",
    "DROPOUT=True\n",
    "numwins=500\n",
    "\n",
    "cnn = CNNFragility(numwins=numwins, \n",
    "                   imsize=imsize,\n",
    "                  n_colors=n_colors, \n",
    "                  num_classes=num_classes, \n",
    "                  num_timesteps=num_timesteps,\n",
    "                  DROPOUT=DROPOUT)\n",
    "cnn.buildmodel()\n",
    "cnn.summaryinfo()\n",
    "print(cnn.model.input_shape)\n",
    "\n",
    "# SVG(model_to_dot(cnn.model).create(prog='dot', format='svg'))\n",
    "print(cnn.model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 500, 1)\n",
      "(None, 7552)\n",
      "Tensor(\"input_3:0\", shape=(?, 500, 1), dtype=float32)\n",
      "Tensor(\"flatten_3/Reshape:0\", shape=(?, ?), dtype=float32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 500, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 498, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 496, 32)           3104      \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 494, 32)           3104      \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 492, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 246, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 244, 64)           6208      \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 242, 64)           12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 121, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 119, 128)          24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 59, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 7552)              0         \n",
      "=================================================================\n",
      "Total params: 52,704\n",
      "Trainable params: 52,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cnn.model1d.input_shape)\n",
    "print(cnn.model1d.output_shape)\n",
    "print(cnn.model1d.input)\n",
    "print(cnn.model1d.output)\n",
    "print(cnn.model1d.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 32, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 2, 2, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 157,344\n",
      "Trainable params: 157,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cnn.model2d.input_shape)\n",
    "print(cnn.model2d.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Training Procedure for Fragility Auxiliary Input\n",
    "\n",
    "**To Do:**\n",
    "* Create a robust pipeline that is not dependent on how data is formatted.\n",
    "    * data should be formatted as:\n",
    "    - include, or don't include seizure period\n",
    "    - length of window\n",
    "    - length of window before seizure\n",
    "    - length of window after seizure\n",
    "    - how to pad\n",
    "    - if seizure onset/offset times are not available\n",
    "    - include data that is not success as well (sometimes they may capture certain areas of true epileptogenicity)\n",
    "* How does one deal with these instances and handle the data if it is \"noisy\"\n",
    "\n",
    "Ideas:\n",
    "* Loss function that is dependent on the Engel score\n",
    "* Loss function that is create a noisy instance of where onset/offset times occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.train import traincnnaux\n",
    "from model.train.fragaux.processdata import SplitData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignoring  la04_ictal_pertmodel.npz\n",
      "ignoring  la04_inter_pertmodel.npz\n",
      "ignoring  la06_ictal_pertmodel.npz\n",
      "ignoring  la06_inter_pertmodel.npz\n",
      "ignoring  la08_ictal_pertmodel.npz\n",
      "ignoring  la08_inter_pertmodel.npz\n",
      "ignoring  la09_ictal_pertmodel.npz\n",
      "ignoring  la09_inter_pertmodel.npz\n",
      "ignoring  la10_ictal_pertmodel.npz\n",
      "ignoring  la10_inter_pertmodel.npz\n",
      "ignoring  la11_ictal_pertmodel.npz\n",
      "ignoring  la11_inter_pertmodel.npz\n",
      "ignoring  la12_ictal_pertmodel.npz\n",
      "ignoring  la13_ictal_pertmodel.npz\n",
      "ignoring  la13_inter_pertmodel.npz\n",
      "ignoring  la15_ictal_pertmodel.npz\n",
      "ignoring  la15_inter_pertmodel.npz\n",
      "ignoring  la16_ictal_pertmodel.npz\n",
      "ignoring  la16_inter_pertmodel.npz\n",
      "ignoring  la17_ictal_pertmodel.npz\n",
      "ignoring  pt6sz3_pertmodel.npz\n",
      "ignoring  pt6sz4_pertmodel.npz\n",
      "ignoring  pt6sz5_pertmodel.npz\n",
      "ignoring  pt7sz19_pertmodel.npz\n",
      "ignoring  pt7sz21_pertmodel.npz\n",
      "ignoring  pt7sz22_pertmodel.npz\n",
      "ignoring  jh103aslp1_pertmodel.npz\n",
      "ignoring  jh103aw1_pertmodel.npz\n",
      "ignoring  jh103sz1_pertmodel.npz\n",
      "ignoring  jh103sz2_pertmodel.npz\n",
      "ignoring  jh103sz3_pertmodel.npz\n",
      "ignoring  ummc001_sz1_pertmodel.npz\n",
      "ignoring  ummc001_sz2_pertmodel.npz\n",
      "ignoring  ummc001_sz3_pertmodel.npz\n",
      "ignoring  ummc007_sz1_pertmodel.npz\n",
      "ignoring  ummc007_sz2_pertmodel.npz\n",
      "ignoring  ummc007_sz3_pertmodel.npz\n",
      "ignoring  ummc008_sz1_pertmodel.npz\n",
      "ignoring  ummc008_sz2_pertmodel.npz\n",
      "ignoring  ummc008_sz3_pertmodel.npz\n",
      "ignoring  ummc009_sz1_pertmodel.npz\n",
      "ignoring  ummc009_sz2_pertmodel.npz\n",
      "ignoring  ummc009_sz3_pertmodel.npz\n",
      "ignoring  la09_ictal_2_pertmodel.npz\n",
      "ignoring  id008_gc_sz2_pertmodel.npz\n",
      "ignoring  id008_gc_sz3_pertmodel.npz\n",
      "ignoring  id013_pg_sz1_pertmodel.npz\n",
      "ignoring  id013_pg_sz2_pertmodel.npz\n",
      "We have 81 datasets\n"
     ]
    }
   ],
   "source": [
    "listofpats = [\n",
    "    'jh105',\n",
    "    'pt1', 'pt2', 'pt3',\n",
    "    'pt8', 'pt11', 'pt13', 'pt15'\n",
    "    'pt16', 'pt17',\n",
    "    'la01',\n",
    "    'la02', 'la03',\n",
    "    'la05', 'la07',\n",
    "    'ummc002', 'ummc003',\n",
    "    'ummc004', 'ummc005',\n",
    "    'ummc006', \n",
    "#     'ummc008',\n",
    "#     'id003', 'id004', 'id005', \n",
    "#     'id008', 'id010', 'id013'\n",
    "#     'ummc001', 'ummc007', 'ummc009'\n",
    "]\n",
    "\n",
    "rawdatadir = '/Volumes/ADAM LI/pydata/converted/'\n",
    "datadir = '/Volumes/ADAM LI/pydata/output/monopolar/pert/'\n",
    "datamunger = SplitData(pcsize, numwins)\n",
    "datamunger.loaddirofdata(datadir, listofpats)\n",
    "\n",
    "print(\"We have %i datasets\" % len(datamunger.datafilepaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/ADAM LI/pydata/output/monopolar/pert/la01_ictal/la01_ictal_pertmodel.npz\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(datamunger.datafilepaths[0])\n",
    "print(numwins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "type error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nantype error in birth date probably, so just setting to nan"
     ]
    }
   ],
   "source": [
    "datamunger.formatdata(rawdatadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6079\n",
      "6079\n",
      "6079\n"
     ]
    }
   ],
   "source": [
    "print(len(datamunger.ylabels))\n",
    "print(len(datamunger.aux_data))\n",
    "print(len(datamunger.main_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup training scheme for data\n",
    "datamunger.trainingscheme(scheme='rand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcsize = 40\n",
    "numwins = 500\n",
    "NUM_EPOCHS = 100\n",
    "AUGMENT = True\n",
    "batch_size = 32\n",
    "\n",
    "tempdatadir = 'test'\n",
    "\n",
    "trainer = traincnnaux.TrainFragAux(cnn.model, numwins, batch_size, NUM_EPOCHS, AUGMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = datamunger.class_weight\n",
    "Xmain_train = datamunger.Xmain_train\n",
    "Xaux_train = datamunger.Xaux_train\n",
    "y_train = datamunger.y_train\n",
    "Xmain_test = datamunger.Xmain_test\n",
    "Xaux_test = datamunger.Xaux_test\n",
    "y_test = datamunger.y_test\n",
    "\n",
    "trainer.loadformatteddata(Xmain_train, Xmain_test, Xaux_train, Xaux_test, \n",
    "                          y_train, y_test, class_weight)\n",
    "trainer.configure(tempdatadir)\n",
    "trainer.loadgenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
