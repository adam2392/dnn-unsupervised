{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing TVB Simulated FFT Maps\n",
    "\n",
    "Here, I run through the FFT computed data to create the images that will be fed into the deep learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../dnn/')\n",
    "sys.path.append('../dnn/')\n",
    "import time\n",
    "import numpy as np\n",
    "# np.random.seed(1234)\n",
    "import math as m\n",
    "import os\n",
    "\n",
    "import processing\n",
    "import processing.preprocessfft\n",
    "from processing.util import DataHandler\n",
    "import peakdetect\n",
    "\n",
    "# import DNN frameworks\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import ntpath\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['phase', 'timepoints', 'freqs', 'power', 'metadata']\n",
      "dict_keys(['gainmat', 'x0norm', b'stepsize', 'pz', 'onsettimes', 'seeg_xyz', b'winsize', 'x0ez', 'regions_centers', 'regions', 'epiparams', 'offsettimes', b'seizoffsets', 'x0pz', 'ez', 'pzindices', 'patient', 'samplerate', b'seizonsets', 'ezindices', 'chanlabels'])\n"
     ]
    }
   ],
   "source": [
    "datadir = '/Volumes/ADAM LI/pydata/output/outputfft/tvbsim/full/win500_step250/'\n",
    "\n",
    "testfilename = 'id008_gc_dist-1.0_fftmodel.npz'\n",
    "\n",
    "data = np.load(os.path.join(datadir, testfilename), encoding='bytes')\n",
    "metadata = data['metadata'].item()\n",
    "print(data.keys())\n",
    "print(metadata.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Through the Simulated FFT Computations\n",
    "\n",
    "- get all the datafiles\n",
    "- compute into images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "/Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull\n"
     ]
    }
   ],
   "source": [
    "# get all datafiles for the fft maps\n",
    "fftdatadir = '/Volumes/ADAM LI/pydata/output/outputfft/tvbsim/full/'\n",
    "# Get ALL datafiles from all downstream files\n",
    "datafiles = []\n",
    "for root, dirs, files in os.walk(fftdatadir):\n",
    "    for file in files:\n",
    "        if '.DS' not in file:\n",
    "            datafiles.append(os.path.join(root, file))\n",
    "print(len(datafiles))\n",
    "# print(datafiles[7:])\n",
    "\n",
    "expname = 'expfull'\n",
    "trainimagedir = os.path.join('/Volumes/ADAM LI/pydata/dnn/traindata_fft/', \n",
    "                        expname)\n",
    "if not os.path.exists(trainimagedir):\n",
    "    os.makedirs(trainimagedir)\n",
    "print(trainimagedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish frequency bands\n",
    "freqbands = {\n",
    "        'dalpha':[0,15],\n",
    "        'beta':[15,30],\n",
    "        'gamma':[30,90],\n",
    "        'high':[90,200],\n",
    "    }\n",
    "postprocessfft = processing.preprocessfft.PreProcess(freqbands=freqbands)\n",
    "\n",
    "winsizems = 500\n",
    "stepsizems = 250\n",
    "typetransform = 'fourier'\n",
    "mtbandwidth = 4\n",
    "mtfreqs = []\n",
    "def path_leaf(path):\n",
    "    head, tail = ntpath.split(path)\n",
    "    return tail or ntpath.basename(head)\n",
    "def decodebytes(metadata):\n",
    "    def convert(data):\n",
    "        if isinstance(data, bytes):  return data.decode('ascii')\n",
    "        if isinstance(data, dict):   return dict(map(convert, data.items()))\n",
    "        if isinstance(data, tuple):  return map(convert, data)\n",
    "        return data\n",
    "    try:\n",
    "        metadata = {k.decode(\"utf-8\"): (v.decode(\"utf-8\") if isinstance(v, bytes) else v) for k,v in metadata.items()}\n",
    "    except AttributeError:\n",
    "        print('trying to convert metadata bytes to unicode')\n",
    "    for key in metadata.keys():\n",
    "        metadata[key] = convert(metadata[key])\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "trying to convert metadata bytes to unicode\n",
      "dict_keys(['gainmat', 'x0norm', b'stepsize', 'pz', 'onsettimes', 'seeg_xyz', b'winsize', 'x0ez', 'regions_centers', 'regions', 'epiparams', 'offsettimes', b'seizoffsets', 'x0pz', 'ez', 'pzindices', 'patient', 'samplerate', b'seizonsets', 'ezindices', 'chanlabels'])\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "Patient is:  id008_gc\n",
      "file id is:  id008_gc_dist11.0\n",
      "\n",
      "\n",
      "\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "(103, 4, 159)\n",
      "(103, 2)\n",
      "(103, 4, 159)\n",
      "(159, 103)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id008_gc_dist11.0_fftmodel\n",
      "1\n",
      "trying to convert metadata bytes to unicode\n",
      "dict_keys(['gainmat', 'x0norm', b'stepsize', 'pz', 'onsettimes', 'seeg_xyz', b'winsize', 'x0ez', 'regions_centers', 'regions', 'epiparams', 'offsettimes', b'seizoffsets', 'x0pz', 'ez', 'pzindices', 'patient', 'samplerate', b'seizonsets', 'ezindices', 'chanlabels'])\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "Patient is:  id008_gc\n",
      "file id is:  id008_gc_dist13.0\n",
      "\n",
      "\n",
      "\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "(103, 4, 159)\n",
      "(103, 2)\n",
      "(103, 4, 159)\n",
      "(159, 103)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id008_gc_dist13.0_fftmodel\n",
      "2\n",
      "trying to convert metadata bytes to unicode\n",
      "dict_keys(['gainmat', 'x0norm', b'stepsize', 'pz', 'onsettimes', 'seeg_xyz', b'winsize', 'x0ez', 'regions_centers', 'regions', 'epiparams', 'offsettimes', b'seizoffsets', 'x0pz', 'ez', 'pzindices', 'patient', 'samplerate', b'seizonsets', 'ezindices', 'chanlabels'])\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "Patient is:  id008_gc\n",
      "file id is:  id008_gc_dist-1.0\n",
      "\n",
      "\n",
      "\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "(103, 4, 159)\n",
      "(103, 2)\n",
      "(103, 4, 159)\n",
      "(159, 103)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id008_gc_dist-1.0_fftmodel\n",
      "3\n",
      "trying to convert metadata bytes to unicode\n",
      "dict_keys(['gainmat', 'x0norm', b'stepsize', 'pz', 'onsettimes', 'seeg_xyz', b'winsize', 'x0ez', 'regions_centers', 'regions', 'epiparams', 'offsettimes', b'seizoffsets', 'x0pz', 'ez', 'pzindices', 'patient', 'samplerate', b'seizonsets', 'ezindices', 'chanlabels'])\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "Patient is:  id008_gc\n",
      "file id is:  id008_gc_dist15.0\n",
      "\n",
      "\n",
      "\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "(103, 4, 159)\n",
      "(103, 2)\n",
      "(103, 4, 159)\n",
      "(159, 103)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id008_gc_dist15.0_fftmodel\n",
      "4\n",
      "dict_keys(['gainmat', 'x0norm', 'ez', 'pz', 'epiparams', 'seeg_xyz', 'winsize', 'x0ez', 'regions_centers', 'regions', 'stepsize', 'offsettimes', 'x0pz', 'onsettimes', 'pzindices', 'patient', 'samplerate', 'ezindices', 'chanlabels'])\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "Patient is:  id013_pg\n",
      "file id is:  id013_pg_dist1.0\n",
      "\n",
      "\n",
      "\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "(59, 4, 159)\n",
      "(59, 2)\n",
      "(59, 4, 159)\n",
      "(159, 59)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id013_pg_dist1.0_fftmodel\n",
      "5\n",
      "dict_keys(['gainmat', 'x0norm', 'ez', 'pz', 'epiparams', 'seeg_xyz', 'winsize', 'x0ez', 'regions_centers', 'regions', 'stepsize', 'offsettimes', 'x0pz', 'onsettimes', 'pzindices', 'patient', 'samplerate', 'ezindices', 'chanlabels'])\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "Patient is:  id013_pg\n",
      "file id is:  id013_pg_dist9.0\n",
      "\n",
      "\n",
      "\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "(59, 4, 159)\n",
      "(59, 2)\n",
      "(59, 4, 159)\n",
      "(159, 59)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id013_pg_dist9.0_fftmodel\n",
      "6\n",
      "trying to convert metadata bytes to unicode\n",
      "dict_keys(['gainmat', 'x0norm', b'stepsize', 'pz', 'onsettimes', 'seeg_xyz', b'winsize', 'x0ez', 'regions_centers', 'regions', 'epiparams', 'offsettimes', b'seizoffsets', 'x0pz', 'ez', 'pzindices', 'patient', 'samplerate', b'seizonsets', 'ezindices', 'chanlabels'])\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "Patient is:  id008_gc\n",
      "file id is:  id008_gc_dist3.0\n",
      "\n",
      "\n",
      "\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "(103, 4, 159)\n",
      "(103, 2)\n",
      "(103, 4, 159)\n",
      "(159, 103)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id008_gc_dist3.0_fftmodel\n",
      "7\n",
      "dict_keys(['gainmat', 'x0norm', 'ez', 'pz', 'epiparams', 'seeg_xyz', 'winsize', 'x0ez', 'regions_centers', 'regions', 'stepsize', 'offsettimes', 'x0pz', 'onsettimes', 'pzindices', 'patient', 'samplerate', 'ezindices', 'chanlabels'])\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "Patient is:  id013_pg\n",
      "file id is:  id013_pg_dist11.0\n",
      "\n",
      "\n",
      "\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "(59, 4, 159)\n",
      "(59, 2)\n",
      "(59, 4, 159)\n",
      "(159, 59)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id013_pg_dist11.0_fftmodel\n",
      "8\n",
      "dict_keys(['gainmat', 'x0norm', 'ez', 'pz', 'epiparams', 'seeg_xyz', 'winsize', 'x0ez', 'regions_centers', 'regions', 'stepsize', 'offsettimes', 'x0pz', 'onsettimes', 'pzindices', 'patient', 'samplerate', 'ezindices', 'chanlabels'])\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "Patient is:  id013_pg\n",
      "file id is:  id013_pg_dist7.0\n",
      "\n",
      "\n",
      "\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "(59, 4, 159)\n",
      "(59, 2)\n",
      "(59, 4, 159)\n",
      "(159, 59)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id013_pg_dist7.0_fftmodel\n",
      "9\n",
      "trying to convert metadata bytes to unicode\n",
      "dict_keys(['gainmat', 'x0norm', 'ez', 'pz', 'onsettimes', 'seeg_xyz', b'winsize', 'x0ez', 'regions_centers', 'regions', b'stepsize', 'offsettimes', b'seizoffsets', 'x0pz', 'epiparams', 'pzindices', 'patient', 'samplerate', b'seizonsets', 'ezindices', 'chanlabels'])\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "Patient is:  id008_gc\n",
      "file id is:  id008_gc_dist5.0\n",
      "\n",
      "\n",
      "\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "(103, 4, 159)\n",
      "(103, 2)\n",
      "(103, 4, 159)\n",
      "(159, 103)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id008_gc_dist5.0_fftmodel\n",
      "10\n",
      "trying to convert metadata bytes to unicode\n",
      "dict_keys(['gainmat', 'x0norm', b'stepsize', 'pz', 'onsettimes', 'seeg_xyz', b'winsize', 'x0ez', 'regions_centers', 'regions', 'epiparams', 'offsettimes', b'seizoffsets', 'x0pz', 'ez', 'pzindices', 'patient', 'samplerate', b'seizonsets', 'ezindices', 'chanlabels'])\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "Patient is:  id008_gc\n",
      "file id is:  id008_gc_dist7.0\n",
      "\n",
      "\n",
      "\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "(103, 4, 159)\n",
      "(103, 2)\n",
      "(103, 4, 159)\n",
      "(159, 103)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id008_gc_dist7.0_fftmodel\n",
      "11\n",
      "dict_keys(['gainmat', 'x0norm', 'ez', 'pz', 'epiparams', 'seeg_xyz', 'winsize', 'x0ez', 'regions_centers', 'regions', 'stepsize', 'offsettimes', 'x0pz', 'onsettimes', 'pzindices', 'patient', 'samplerate', 'ezindices', 'chanlabels'])\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "Patient is:  id013_pg\n",
      "file id is:  id013_pg_dist13.0\n",
      "\n",
      "\n",
      "\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "(59, 4, 159)\n",
      "(59, 2)\n",
      "(59, 4, 159)\n",
      "(159, 59)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id013_pg_dist13.0_fftmodel\n",
      "12\n",
      "dict_keys(['gainmat', 'x0norm', 'ez', 'pz', 'epiparams', 'seeg_xyz', 'winsize', 'x0ez', 'regions_centers', 'regions', 'stepsize', 'offsettimes', 'x0pz', 'onsettimes', 'pzindices', 'patient', 'samplerate', 'ezindices', 'chanlabels'])\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "Patient is:  id013_pg\n",
      "file id is:  id013_pg_dist5.0\n",
      "\n",
      "\n",
      "\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "(59, 4, 159)\n",
      "(59, 2)\n",
      "(59, 4, 159)\n",
      "(159, 59)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id013_pg_dist5.0_fftmodel\n",
      "13\n",
      "trying to convert metadata bytes to unicode\n",
      "dict_keys(['gainmat', 'x0norm', b'stepsize', 'pz', 'onsettimes', 'seeg_xyz', b'winsize', 'x0ez', 'regions_centers', 'regions', 'epiparams', 'offsettimes', b'seizoffsets', 'x0pz', 'ez', 'pzindices', 'patient', 'samplerate', b'seizonsets', 'ezindices', 'chanlabels'])\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "Patient is:  id008_gc\n",
      "file id is:  id008_gc_dist1.0\n",
      "\n",
      "\n",
      "\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "(103, 4, 159)\n",
      "(103, 2)\n",
      "(103, 4, 159)\n",
      "(159, 103)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id008_gc_dist1.0_fftmodel\n",
      "14\n",
      "dict_keys(['gainmat', 'x0norm', 'ez', 'pz', 'epiparams', 'seeg_xyz', 'winsize', 'x0ez', 'regions_centers', 'regions', 'stepsize', 'offsettimes', 'x0pz', 'onsettimes', 'pzindices', 'patient', 'samplerate', 'ezindices', 'chanlabels'])\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "Patient is:  id013_pg\n",
      "file id is:  id013_pg_dist-1.0\n",
      "\n",
      "\n",
      "\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "(59, 4, 159)\n",
      "(59, 2)\n",
      "(59, 4, 159)\n",
      "(159, 59)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id013_pg_dist-1.0_fftmodel\n",
      "15\n",
      "trying to convert metadata bytes to unicode\n",
      "dict_keys(['gainmat', 'x0norm', b'stepsize', 'pz', 'onsettimes', 'seeg_xyz', b'winsize', 'x0ez', 'regions_centers', 'regions', 'epiparams', 'offsettimes', b'seizoffsets', 'x0pz', 'ez', 'pzindices', 'patient', 'samplerate', b'seizonsets', 'ezindices', 'chanlabels'])\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "Patient is:  id008_gc\n",
      "file id is:  id008_gc_dist9.0\n",
      "\n",
      "\n",
      "\n",
      "(103,)\n",
      "(103, 251, 159)\n",
      "(103, 4, 159)\n",
      "(103, 2)\n",
      "(103, 4, 159)\n",
      "(159, 103)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id008_gc_dist9.0_fftmodel\n",
      "16\n",
      "dict_keys(['gainmat', 'x0norm', 'ez', 'pz', 'epiparams', 'seeg_xyz', 'winsize', 'x0ez', 'regions_centers', 'regions', 'stepsize', 'offsettimes', 'x0pz', 'onsettimes', 'pzindices', 'patient', 'samplerate', 'ezindices', 'chanlabels'])\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "Patient is:  id013_pg\n",
      "file id is:  id013_pg_dist3.0\n",
      "\n",
      "\n",
      "\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "(59, 4, 159)\n",
      "(59, 2)\n",
      "(59, 4, 159)\n",
      "(159, 59)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id013_pg_dist3.0_fftmodel\n",
      "17\n",
      "dict_keys(['gainmat', 'x0norm', 'ez', 'pz', 'epiparams', 'seeg_xyz', 'winsize', 'x0ez', 'regions_centers', 'regions', 'stepsize', 'offsettimes', 'x0pz', 'onsettimes', 'pzindices', 'patient', 'samplerate', 'ezindices', 'chanlabels'])\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "Patient is:  id013_pg\n",
      "file id is:  id013_pg_dist15.0\n",
      "\n",
      "\n",
      "\n",
      "(59,)\n",
      "(59, 251, 159)\n",
      "(59, 4, 159)\n",
      "(59, 2)\n",
      "(59, 4, 159)\n",
      "(159, 59)\n",
      "(159, 4, 32, 32)9/159\n",
      "(159, 4, 32, 32)\n",
      "saved at  /Volumes/ADAM LI/pydata/dnn/traindata_fft/expfull/id013_pg_dist15.0_fftmodel\n"
     ]
    }
   ],
   "source": [
    "# define the data handler \n",
    "datahandler = DataHandler()\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# rawdatadir = '/Volumes/ADAM LI/pydata/convertedtng/'\n",
    "checkrawdata = lambda patient: os.path.join(rawdatadir, patient)\n",
    "\n",
    "for idx, datafile in enumerate(datafiles):\n",
    "    print(idx)\n",
    "    # perform file identification\n",
    "    dirname = os.path.dirname(datafile)\n",
    "    filename = path_leaf(datafile)\n",
    "    fileid = filename.split('_fftmodel')[0]\n",
    "    patient = '_'.join(fileid.split('_')[0:2])\n",
    "    \n",
    "    # load in the data for this fft computation\n",
    "    fftdata = np.load(datafile, encoding='bytes')\n",
    "    power = fftdata['power']\n",
    "    freqs = fftdata['freqs']\n",
    "    timepoints = fftdata['timepoints']\n",
    "    metadata = fftdata['metadata'].item()\n",
    "    \n",
    "    # extract the metadata needed\n",
    "    metadata = decodebytes(metadata) \n",
    "    print(metadata.keys())\n",
    "    onset_times = metadata['onsettimes']\n",
    "    offset_times = metadata['offsettimes']\n",
    "    seeg_labels = metadata['chanlabels']\n",
    "    seeg_xyz = metadata['seeg_xyz']\n",
    "    samplerate = metadata['samplerate']\n",
    "    \n",
    "    # get indices of channels that we have seeg_xyz for\n",
    "    power = np.abs(power)\n",
    "    \n",
    "    # get overlapping indices on seeg with xyz\n",
    "    xyzinds = [i for i,x in enumerate(seeg_labels) if any(thing==x for thing in seeg_labels)]\n",
    "    seeg_xyz = seeg_xyz[xyzinds,:]\n",
    "    \n",
    "    print(\"Patient is: \", patient)\n",
    "    print(\"file id is: \", fileid)\n",
    "#     print(dirname)\n",
    "#     print(\"Filename loaded is: \", filename)\n",
    "    print(\"\\n\\n\")\n",
    "    print(seeg_labels.shape)\n",
    "    print(power.shape)\n",
    "    assert power.shape[0] == seeg_xyz.shape[0]\n",
    "    assert power.shape[0] == len(seeg_labels)\n",
    "    \n",
    "    # postprocess fft into bins\n",
    "    power = postprocessfft.binFrequencyValues(power, freqs)\n",
    "\n",
    "    # project xyz data\n",
    "    seeg_xyz = pca.fit_transform(seeg_xyz)\n",
    "    \n",
    "#     print(seeg_xyz.shape)\n",
    "#     print(power.shape)\n",
    "    # Tensor of size [samples, freqbands, W, H] containing generated images.\n",
    "    image_tensor = datahandler.gen_images(seeg_xyz, power, \n",
    "                            n_gridpoints=32, normalize=False, augment=False, \n",
    "                            pca=False, std_mult=0., edgeless=False)\n",
    "    print(image_tensor.shape)\n",
    "    # compute ylabels    \n",
    "    ylabels = datahandler.computelabels(onset_times, offset_times, timepoints)\n",
    "    # instantiate metadata hash table\n",
    "    metadata = dict()\n",
    "    metadata['chanlabels'] = seeg_labels\n",
    "    metadata['seeg_xyz'] = seeg_xyz\n",
    "    metadata['ylabels'] = ylabels\n",
    "    metadata['samplerate'] = samplerate\n",
    "    metadata['timepoints'] = timepoints\n",
    "    \n",
    "    # save image and meta data\n",
    "    imagefilename = os.path.join(trainimagedir, filename.split('.npz')[0])\n",
    "    print(image_tensor.shape)\n",
    "    print('saved at ', imagefilename)\n",
    "    np.savez_compressed(imagefilename, image_tensor=image_tensor, metadata=metadata)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
