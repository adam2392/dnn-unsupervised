{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Datasets \n",
    "\n",
    "This will be similar to the other notebook for loading datasets, but mainly focused on the fragility computations. This is simply to look at loading the data if there are some nuances.\n",
    "\n",
    "5/17/18: This would not be expected though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from processing.fftdataset import FFT2DImageDataset\n",
    "from util.augment import *\n",
    "from util import augmentations\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/Volumes/ADAM LI/pydata/output_fft/tngcenter/win500_step250/'\n",
    "root_dir = '/Volumes/ADAM LI/pydata/output_fft/asimages/realtng/'\n",
    "datasetnames = []\n",
    "\n",
    "chanmeans = [0.485, 0.456, 0.406]\n",
    "chanstd = [0.229, 0.224, 0.225]\n",
    "imsize = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(mode='RGBA'),\n",
    "#     transforms.RandomApply(transforms, p=0.5),\n",
    "#     augmentations.RandomLightingNoise(),\n",
    "#     transforms.RandomSizedCrop(2),  \n",
    "#     transforms.CenterCrop(3),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=5, \n",
    "                            resample=False, \n",
    "                            expand=False, \n",
    "                            center=None),\n",
    "    transforms.RandomAffine(degrees=5, \n",
    "                            translate=(0.1,0.1), \n",
    "                            scale=None, \n",
    "                            shear=5, \n",
    "                            resample=False, \n",
    "                            fillcolor=0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=chanmeans,    # apply normalization along channel axis\n",
    "                         std=chanstd),\n",
    "    augmentations.InjectNoise(),\n",
    "])\n",
    "\n",
    "\n",
    "dataset = FFT2DImageDataset(root_dir, datasetnames, transform=data_transform)\n",
    "dataloader = DataLoader(dataset, \n",
    "                    batch_size=1,\n",
    "                    shuffle=True, \n",
    "                    num_workers=1)\n",
    "\n",
    "print(dataloader)\n",
    "print(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    images_batch, ylabels = sample_batched[0], sample_batched[1]\n",
    "    print(i_batch)\n",
    "    print(images_batch.shape)\n",
    "    print(ylabels.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
