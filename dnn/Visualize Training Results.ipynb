{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('/Users/adam2392/Documents/fragility_analysis/')\n",
    "import fragility.util.utils as futil\n",
    "import datainterface.patient as Pat\n",
    "# from fragility.signalprocessing import frequencyanalysis\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.io\n",
    "\n",
    "import processing.util as util\n",
    "import processing.frequencytransform as ft\n",
    "import peakdetect\n",
    "import processing.preprocessfft as preprocess\n",
    "\n",
    "# sys.path.append('/Users/adam2392/Documents/tvb/')\n",
    "# sys.path.append('/Users/adam2392/Documents/tvb/_tvbdata/')\n",
    "# sys.path.append('/Users/adam2392/Documents/tvb/_tvblibrary/')\n",
    "# from tvb.simulator.lab import *\n",
    "# import tvbsim.util\n",
    "\n",
    "from natsort import natsorted\n",
    "import ntpath\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def path_leaf(path):\n",
    "    head, tail = ntpath.split(path)\n",
    "    return tail or ntpath.basename(head)\n",
    "\n",
    "def _gettimepoints(numsignals, numwinsamps, numstepsamps):\n",
    "    # create array of indices of window start times\n",
    "    timestarts = np.arange(0, numsignals-numwinsamps+1, numstepsamps)\n",
    "    # create array of indices of window end times\n",
    "    timeends = np.arange(numwinsamps-1, numsignals, numstepsamps)\n",
    "    # create the timepoints array for entire data array\n",
    "    timepoints = np.append(timestarts.reshape(len(timestarts), 1), timeends.reshape(len(timestarts), 1), axis=1)\n",
    "    return timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "expname = 'cnn'\n",
    "\n",
    "# dirs for the training data from the model \n",
    "datadir = os.path.join('/Volumes/ADAM LI/pydata/dnn/', expname)\n",
    "tempdir = os.path.join(datadir, '_temp')\n",
    "finaldir = os.path.join(datadir, '_final')\n",
    "\n",
    "# the original raw data dir\n",
    "metadatadir = '/Volumes/ADAM LI/pydata/metadata/'    \n",
    "traindir = os.path.join('/Volumes/ADAM LI/pydata/traindata/fft/', expname)\n",
    "\n",
    "# Get ALL datafiles from all downstream files\n",
    "datafiles = []\n",
    "for root, dirs, files in os.walk(datadir):\n",
    "    for file in files:\n",
    "        datafiles.append(os.path.join(root, file))\n",
    "print(len(datafiles))\n",
    "# print(datafiles[50:])\n",
    "# print(datafiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Final History\n",
    "\n",
    "Investigate the history object saved at the final point in time and see how training proceeded. Get a value of the accuracy and precision of the neural network.\n",
    "\n",
    "Visualize any other important metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize The Diversity of the Data That We Used\n",
    "\n",
    "Visualize the diversity of the data we used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "dnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
