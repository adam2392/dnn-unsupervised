{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sys\n",
    "import os\n",
    "from time import time\n",
    "np.random.seed(1234567)\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('/Users/adam2392/Documents/tvb/')\n",
    "sys.path.append('/Users/adam2392/Documents/tvb/_tvbdata/')\n",
    "sys.path.append('/Users/adam2392/Documents/tvb/_tvblibrary/')\n",
    "import processing.preprocessfft as preprocess\n",
    "import processing.frequencytransform as ft\n",
    "\n",
    "sys.path.append('/Users/adam2392/Documents/fragility_analysis/')\n",
    "import fragility\n",
    "import fragility.util.utils as futil\n",
    "import datainterface\n",
    "from datainterface import patient as Pat\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Data\n",
    "\n",
    "Data will be stored either as edf files, or .eeg files. We can use our eegreader to read .eeg files (if no bugs) and pyedflib to read the .edf files.\n",
    "\n",
    "Then, we want to make sure we have the vital information regarding each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading header from <open file '/Users/adam2392/Downloads/tngrawdata/id001_ac/crise1/crise cabrol.eeg', mode 'rb' at 0x113dc8f60>\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "<open file '/Users/adam2392/Downloads/tngrawdata/id001_ac/crise1/crise cabrol.eeg', mode 'rb' at 0x113dc8f60> is not a valid EEG file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-81b8fc292922>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/adam2392/Downloads/tngrawdata/id001_ac/crise1/crise cabrol.eeg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meegreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatainterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_eeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEEG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/adam2392/Documents/fragility_analysis/datainterface/read_eeg.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, verbose)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mident\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentificateur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coherence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'COHERENCE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%r is not a valid EEG file'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;31m# go to data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'firstBlockPos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: <open file '/Users/adam2392/Downloads/tngrawdata/id001_ac/crise1/crise cabrol.eeg', mode 'rb' at 0x113dc8f60> is not a valid EEG file"
     ]
    }
   ],
   "source": [
    "filename = '/Users/adam2392/Downloads/tngrawdata/id001_ac/crise1/crise cabrol.eeg'\n",
    "eegreader = datainterface.read_eeg.EEG(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### 1. first run data conversion\n",
    "patient = 'id001_ac'\n",
    "outputdir = os.path.join('/Volumes/ADAM LI/pydata/convertedtng/', patient)\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "\n",
    "edfdir = os.path.join('/Users/adam2392/Downloads/tngrawdata/', patient)\n",
    "edffile = os.path.join(edfdir, '')\n",
    "edffile ='/Users/adam2392/Downloads/tngrawdata/id001_ac/crise2/crise_fin/091126B-BEX_0006.edf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datainterface.dataconversion:Initialized EDFConverter object.\n",
      "INFO:datainterface.dataconversion:File is edf format: /Users/adam2392/Downloads/tngrawdata/id001_ac/crise2/crise_fin/091126B-BEX_0006.edf\n",
      "INFO:datainterface.dataconversion:Closing edf file! Raw data should be saved as numpy at /Volumes/ADAM LI/pydata/convertedtng/id001_ac/id001_ac_rawnpy.npy\n",
      "INFO:datainterface.dataconversion:Closing edf file! Headers meta data should be saved as csv at /Volumes/ADAM LI/pydata/convertedtng/id001_ac/id001_ac_headers.csv\n",
      "INFO:datainterface.dataconversion:Channel meta data should be saved as csv at /Volumes/ADAM LI/pydata/convertedtng/id001_ac/id001_ac_chans.csv\n",
      "INFO:datainterface.dataconversion:Annotations meta data should be saved as csv at /Volumes/ADAM LI/pydata/convertedtng/id001_ac/id001_ac_annotations.csv\n"
     ]
    }
   ],
   "source": [
    "#### 1. setting filename \n",
    "npyfile = os.path.join(outputdir,  patient.lower() + '_rawnpy.npy')\n",
    "chanfile =  os.path.join(outputdir,  patient.lower() + '_chans.csv')\n",
    "headerfile = os.path.join(outputdir,  patient.lower() + '_headers.csv')\n",
    "annotationsfile = os.path.join(outputdir, patient.lower() + '_annotations.csv')\n",
    "\n",
    "# convert data into csv files and numpy raw data file\n",
    "converter = datainterface.dataconversion.EDFConverter(edffile)\n",
    "converter.edfrawtonumpy(npyfile)\n",
    "converter.edfmetatocsv(headerfile, \\\n",
    "                    chanfile, \\\n",
    "                    annotationsfile)\n",
    "f1=open(os.path.join(outputdir, 'datadescrip.txt'), 'w+')\n",
    "f1.write(edffile)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default method of tapering is eigen\n",
      "/Volumes/ADAM LI/pydata/testdata/fft/id001_ac\n"
     ]
    }
   ],
   "source": [
    "expname = 'id001_ac'\n",
    "traindir = os.path.join('/Volumes/ADAM LI/pydata/testdata/fft/', \n",
    "                        expname)\n",
    "if not os.path.exists(traindir):\n",
    "    os.makedirs(traindir)\n",
    "\n",
    "# establish frequency bands\n",
    "freqbands = {\n",
    "        'dalpha':[0,15],\n",
    "        'beta':[15,30],\n",
    "        'gamma':[30,90],\n",
    "        'high':[90,200],\n",
    "    }\n",
    "postprocessfft = preprocess.PreProcess(freqbands=freqbands)\n",
    "# FFT Parameters\n",
    "fs = 1000\n",
    "winsize = 1000 # winsize in milliseconds\n",
    "stepsize = 500 # stepsize in milliseconds\n",
    "typetransform = 'fourier'\n",
    "mtbandwidth = 4\n",
    "mtfreqs = []\n",
    "\n",
    "mtaper = ft.MultiTaperFFT(winsize, stepsize, fs, mtbandwidth, mtfreqs)\n",
    "\n",
    "print(traindir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Run FFT Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractrawdata(patient, datadir, fileend=None):\n",
    "    '''\n",
    "    This function takes in:\n",
    "    1. patient name\n",
    "    2. results directory (perturbation model)\n",
    "    3. data directory, where all the raw metadata is held\n",
    "    \n",
    "    And extracts the data necessary for plotting\n",
    "    '''\n",
    "    # files to get resulting data and the original raw data / annotations\n",
    "    rawdatafile = os.path.join(datadir,  patient + fileend, patient+'_rawnpy.npy')\n",
    "    chanfile =  os.path.join(datadir,  patient + fileend, patient + '_chans.csv')\n",
    "    headerfile = os.path.join(datadir,  patient + fileend, patient + '_headers.csv')\n",
    "    annotationsfile = os.path.join(datadir,  patient + fileend, patient + '_annotations.csv')\n",
    "\n",
    "    ################################ 1. LOAD DATA ###########################\n",
    "    # instantiate a datainterface object to analyze data\n",
    "    patieeg = Pat.PatientIEEG(patient, clinoutcome=None, engelscore=None, logfile=None)\n",
    "    # get relevant channel data\n",
    "    patid, seizid = futil.splitpatient(patient)\n",
    "    included_chans, onsetchans, clinresult = fragility.util.utils.returnindices(patid, seizid)\n",
    "    \n",
    "    # set metadata to be used in analysis\n",
    "    patieeg.setincludedchans(included_chans)\n",
    "    patieeg.setmetadata_fromfile(headersfile=headerfile)\n",
    "    patieeg.setchannels_fromfile(channelsfile=chanfile)\n",
    "    patieeg.setannotations_fromfile(annotationsfile=annotationsfile)\n",
    "\n",
    "    # get the data from files\n",
    "    data = np.load(rawdatafile)\n",
    "    \n",
    "    return patieeg, data, included_chans, onsetchans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datainterface.patient:Initialized Patient IEEG object. Should run channels, metadata and annotations next!\n",
      "INFO:datainterface.patient:Ran setup of meta data!\n",
      "INFO:datainterface.patient:Ran setup of channels data!\n",
      "INFO:datainterface.patient:Ran setup of annotations data!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<datainterface.patient.PatientIEEG object at 0x1116ee160>\n",
      "(84, 306688)\n",
      "(0,)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "datadir = '/Volumes/ADAM LI/pydata/convertedtng/'\n",
    "patient='id001_ac'\n",
    "# load in the data for a real patient\n",
    "patieeg, rawdata, included_chans, onsetchans = extractrawdata(patient, datadir, '_sz2')\n",
    "\n",
    "rawdata=rawdata.T\n",
    "print(patieeg)\n",
    "print(rawdata.shape)\n",
    "print(included_chans.shape)\n",
    "print(onsetchans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded raw data in MultiTaperFFT!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam2392/Documents/dnn-unsupervised/.venv/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "../processing/preprocessfft.py:80: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  power_binned[:,idx,:] = np.mean(power[:,indices[0]:indices[1]+1,:], axis=1) #[np.newaxis,:,:]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'onset_indice' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ad65d4e15edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moffsettime\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0moffset_indice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfragility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverttimestowindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimepoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsettime\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mseiztimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monset_indice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset_indice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m filename = os.path.join(traindir, \n",
      "\u001b[0;31mNameError\u001b[0m: name 'onset_indice' is not defined"
     ]
    }
   ],
   "source": [
    "metadatadir = os.path.join('/Volumes/ADAM LI/pydata/metadata/', patient)  \n",
    "# load in seegxyz\n",
    "seeg = pd.read_csv(os.path.join(metadatadir, \"seeg.txt\"), names=['x', 'y', 'z'], delim_whitespace=True)\n",
    "chanlabels = seeg.index\n",
    "seeg_xyz = seeg.as_matrix() \n",
    "    \n",
    "# run FFT analysis\n",
    "mtaper.loadrawdata(rawdata)\n",
    "power, freqs, timepoints, _ = mtaper.mtwelch()\n",
    "power = postprocessfft.binFrequencyValues(power, freqs)\n",
    "\n",
    "onsettime = patieeg.onset_time\n",
    "offsettime = patieeg.offset_time\n",
    "# get seiztimes given onset/offset\n",
    "if onsettime: \n",
    "    onset_indice = fragility.util.utils.converttimestowindow(timepoints, onsettime * fs)\n",
    "if offsettime:\n",
    "    offset_indice = fragility.util.utils.converttimestowindow(timepoints, offsettime * fs)\n",
    "seiztimes = zip(onset_indice, offset_indice)\n",
    "    \n",
    "filename = os.path.join(traindir, \n",
    "                        patient + '_fft.npz')\n",
    "\n",
    "# load xyz data for this particular dataset\n",
    "xyz_data = data['locs']\n",
    "seeg_contacts = data['seeg_contacts']\n",
    "x0ez = data['x0ez']\n",
    "seizonsets = data['seizonsets']\n",
    "seizoffsets = data['seizoffsets']\n",
    "\n",
    "\n",
    "np.savez_compressed(filename, \n",
    "                    power=power, \n",
    "                    timepoints=timepoints,\n",
    "                    seiztimes=seiztimes,\n",
    "                    locs=seeg_xyz,\n",
    "                    seeg_contacts=chanlabels)\n",
    "print(filename)\n",
    "print(power.shape)\n",
    "print(freqs.shape)\n",
    "print(timepoints.shape)\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Run Image Creation for 2D Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expname = 'varydistance_2'\n",
    "datadir = os.path.join('/Volumes/ADAM LI/pydata/dnn/traindata/fft/', expname) \n",
    "\n",
    "# load in meta data\n",
    "project_dir = os.path.join(metadatadir, patient)\n",
    "confile = os.path.join(project_dir, \"connectivity.zip\")\n",
    "\n",
    "# get the regions, and region_centers from connectivity\n",
    "reader = util.ZipReader(confile)\n",
    "region_centers = reader.read_array_from_file(\"centres\", use_cols=(1, 2, 3))\n",
    "regions = reader.read_array_from_file(\"centres\", dtype=np.str, use_cols=(0,))\n",
    "\n",
    "\n",
    "\n",
    "# fftdatafile, seeg contacts, \n",
    "datafile = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the data handler \n",
    "datahandler = util.DataHandler()\n",
    "pca = PCA(n_components=2)\n",
    "trainimagedir = os.path.join('/Volumes/ADAM LI/pydata/dnn/testdata/image_2d/', expname)\n",
    "if not os.path.exists(trainimagedir):\n",
    "    os.makedirs(trainimagedir)\n",
    "    \n",
    "# loop through each data file and get grid\n",
    "data = np.load(datafile, encoding='bytes')\n",
    "power = data['power']\n",
    "print(power.shape)\n",
    "print(data.keys())\n",
    "\n",
    "# load xyz data for this particular dataset\n",
    "xyz_data = data['locs']\n",
    "seeg_contacts = data['seeg_contacts']\n",
    "x0ez = data['x0ez']\n",
    "seizonsets = data['seizonsets']\n",
    "seizoffsets = data['seizoffsets']\n",
    "timepoints = data['timepoints']\n",
    "\n",
    "# project xyz data\n",
    "if AZIM==1:\n",
    "    print(\"using azim projection to grid image\")\n",
    "    new_locs = []\n",
    "    for ichan in range(0,xyz_data.shape[0]):\n",
    "        new_locs.append(datahandler.azim_proj(xyz_data[ichan,:]))\n",
    "    new_locs = np.asarray(new_locs)\n",
    "if AZIM==0:\n",
    "    print(\"using pca to grid image\")\n",
    "    new_locs = pca.fit_transform(xyz_data)\n",
    "\n",
    "print(seizonsets)\n",
    "print(seizoffsets)\n",
    "ylabels = datahandler.computelabels(seizonsets,seizoffsets, timepoints)\n",
    "\n",
    "if len(seizonsets) <= 1 and seizonsets[0] == np.nan:\n",
    "    print(\"skipping \", datafile)\n",
    "else:\n",
    "    # Tensor of size [samples, freqbands, W, H] containing generated images.\n",
    "    image_tensor = datahandler.gen_images(new_locs, power, \n",
    "                            n_gridpoints=32, normalize=True, augment=False, \n",
    "                            pca=False, std_mult=0.1, edgeless=False)\n",
    "\n",
    "print(image_tensor.shape)\n",
    "# set saving file paths for image and corresponding meta data\n",
    "filename = path_leaf(datafile)\n",
    "imagefilename = os.path.join(trainimagedir, filename)\n",
    "\n",
    "# instantiate metadata hash table\n",
    "metadata = dict()\n",
    "metadata['x0ez'] = x0ez\n",
    "metadata['seeg_contacts'] = seeg_contacts\n",
    "metadata['new_locs'] = new_locs\n",
    "metadata['ylabels'] = ylabels\n",
    "\n",
    "# save image and meta data\n",
    "np.savez(imagefilename, image_tensor=image_tensor, metadata=metadata)\n",
    "\n",
    "print(new_locs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "dnn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
